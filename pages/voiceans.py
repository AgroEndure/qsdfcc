import streamlit as st
from audio_recorder_streamlit import audio_recorder
import openai
from gtts import gTTS
import os

# âœ… Securely fetch API key from Streamlit input or environment variable
def setup_openai_client(api_key):
    if not api_key or not api_key.startswith("sk-"):
        raise ValueError("âŒ Invalid API key. Please enter a valid OpenAI API key.")
    
    openai.api_key = api_key
    st.sidebar.success("âœ… API Key Set Successfully")

# âœ… Function to transcribe Urdu audio using OpenAI Whisper API
def transcribe_audio(audio_path):
    with open(audio_path, "rb") as audio_file:
        transcript = openai.Audio.transcribe(  
            model="whisper-1",  
            file=audio_file,
            language="ur"
        )
    return transcript["text"].strip() if "text" in transcript else ""

# âœ… Function to get AI response in Urdu
def fetch_ai_response(input_text):
    if not input_text:  
        return "Ù…Ø¹Ø°Ø±Øª! Ù…ÛŒÚº Ø¢Ù¾ Ú©ÛŒ Ø¨Ø§Øª Ù†ÛÛŒÚº Ø³Ù† Ø³Ú©Ø§Û” Ø¨Ø±Ø§Û Ú©Ø±Ù… Ø¯ÙˆØ¨Ø§Ø±Û Ø¨ÙˆÙ„ÛŒÚºÛ”"
    
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",  
        messages=[{"role": "user", "content": input_text}],
        temperature=0.7,
        max_tokens=4000
    )
    return response["choices"][0]["message"]["content"]

# âœ… Convert text to Urdu speech using Google TTS
def text_to_audio(text, audio_path):
    tts = gTTS(text=text, lang='ur')
    tts.save(audio_path)

# âœ… Main function to run the app
def main():
    st.sidebar.title("ğŸ”‘ API Key Configuration")
    api_key = st.sidebar.text_input("Ø§Ù¾Ù†Ø§ OpenAI API Ú©Ù„ÛŒØ¯ Ø¯Ø±Ø¬ Ú©Ø±ÛŒÚº", type="password")

    st.title("ğŸ—£ï¸ Aurora SpeakEasy - Ø§Ø±Ø¯Ùˆ")
    st.write("Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÛŒÚ©Ù…! Ù…Ø¬Ú¾ Ø³Û’ Ø¨Ø§Øª Ú©Ø±Ù†Û’ Ú©Û’ Ù„Ø¦Û’ Ù†ÛŒÚ†Û’ Ø±ÛŒÚ©Ø§Ø±ÚˆÙ†Ú¯ Ú©Ø§ Ø¨Ù¹Ù† Ø¯Ø¨Ø§Ø¦ÛŒÚºÛ”")

    if api_key:
        try:
            setup_openai_client(api_key)  # Ensure API key is set correctly
            recorded_audio = audio_recorder()

            if recorded_audio:
                audio_file = "audio.mp3"
                with open(audio_file, "wb") as f:
                    f.write(recorded_audio)

                transcribed_text = transcribe_audio(audio_file)

                if not transcribed_text:  
                    st.write("âš ï¸ Ú©ÙˆØ¦ÛŒ Ø¢ÙˆØ§Ø² Ù†ÛÛŒÚº Ø³Ù†ÛŒ Ú¯Ø¦ÛŒØŒ Ø¨Ø±Ø§Û Ú©Ø±Ù… Ø¯ÙˆØ¨Ø§Ø±Û Ú©ÙˆØ´Ø´ Ú©Ø±ÛŒÚºÛ”")
                    return  

                st.write("ğŸ“ **ØªØ­Ø±ÛŒØ±ÛŒ Ù…ØªÙ†:** ", transcribed_text)

                ai_response = fetch_ai_response(transcribed_text)

                response_audio_file = "audio_response.mp3"
                text_to_audio(ai_response, response_audio_file)

                st.audio(response_audio_file)
                st.write("ğŸ¤– **AI Ú©Ø§ Ø¬ÙˆØ§Ø¨:** ", ai_response)

        except ValueError as e:
            st.sidebar.error(str(e))  # Show API key error
        except openai.error.AuthenticationError:
            st.sidebar.error("âŒ OpenAI API Key Incorrect! Please enter a valid key.")
        except Exception as e:
            st.error(f"âš ï¸ Error: {str(e)}")  # Catch unexpected errors

if __name__ == "__main__":
    main()
